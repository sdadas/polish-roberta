from typing import List
from sacremoses import MosesDetokenizer

emoji = {
    'ðŸ˜€': ':D',
    'ðŸ˜ƒ': ':)',
    'ðŸ˜„': ':)',
    'ðŸ˜': ':)',
    'ðŸ˜†': 'xD',
    'ðŸ˜…': ':)',
    'ðŸ¤£': 'xD',
    'ðŸ˜‚': 'xD',
    'ðŸ™‚': ':)',
    'ðŸ™ƒ': ':)',
    'ðŸ˜‰': ';)',
    'ðŸ˜Š': ':)',
    'ðŸ˜‡': ':)',
    'ðŸ¥°': ':*',
    'ðŸ˜': ':*',
    'ðŸ¤©': ':*',
    'ðŸ˜˜': ':*',
    'ðŸ˜—': ':*',
    'â˜º': ':)',
    'ðŸ˜š': ':*',
    'ðŸ˜‹': ':P',
    'ðŸ˜›': ':P',
    'ðŸ˜œ': ':P',
    'ðŸ˜': ':P',
    'ðŸ¤‘': ':P',
    'ðŸ¤ª': ':P',
    'ðŸ¤—': ':P',
    'ðŸ¤­': ':P',
    'ðŸ¤«': ':|',
    'ðŸ¤”': ':|',
    'ðŸ¤¨': ':|',
    'ðŸ˜': ':|',
    'ðŸ˜‘': ':|',
    'ðŸ˜¶': ':|',
    'ðŸ˜': ':)',
    'ðŸ˜’': ':(',
    'ðŸ™„': ':|',
    'ðŸ¤': ':|',
    'ðŸ˜¬': ':$',
    'ðŸ˜Œ': 'zzz',
    'ðŸ˜”': ':(',
    'ðŸ˜ª': 'zzz',
    'ðŸ¤¤': ':(',
    'ðŸ¤’': ':(',
    'ðŸ¤•': ':(',
    'ðŸ¤¢': ':(',
    'ðŸ¤®': ':(',
    'ðŸ¤§': ':(',
    'ðŸ¥µ': ':(',
    'ðŸ¥¶': ':(',
    'ðŸ¥´': ':(',
    'ðŸ˜µ': ':(',
    'ðŸ¤¯': ':(',
    'ðŸ¤ ': ':)',
    'ðŸ¥³': ':)',
    'ðŸ˜Ž': ':)',
    'ðŸ¤“': ':)',
    'ðŸ§': ':)',
    'ðŸ˜•': ':(',
    'ðŸ˜Ÿ': ':(',
    'ðŸ™': ':(',
    'â˜¹': ':(',
    'ðŸ˜®': ':O',
    'ðŸ˜¯': ':O',
    'ðŸ˜²': ':O',
    'ðŸ˜³': ':(',
    'ðŸ¥º': ':(',
    'ðŸ˜¦': ':(',
    'ðŸ˜§': ':(',
    'ðŸ˜¨': ':(',
    'ðŸ˜°': ':(',
    'ðŸ˜¥': ':(',
    'ðŸ˜¢': ':(',
    'ðŸ˜­': ':(',
    'ðŸ˜±': ':(',
    'ðŸ˜–': ':(',
    'ðŸ˜£': ':(',
    'ðŸ˜ž': ':(',
    'ðŸ˜“': ':(',
    'ðŸ˜©': ':(',
    'ðŸ˜«': ':(',
    'ðŸ¥±': 'zzz',
    'ðŸ˜¤': ':(',
    'ðŸ˜¡': ':(',
    'ðŸ˜ ': ':(',
    'ðŸ¤¬': ':(',
    'ðŸ˜ˆ': ']:->',
    'ðŸ‘¿': ']:->',
    'ðŸ’€': ':(',
    'â˜ ': ':(',
    'ðŸ’‹': ':*',
    'ðŸ’”': ':(',
    'ðŸ’¤': 'zzz'
}

class TextNormalizer(object):

    def __init__(self, detokenize: bool=True, replace_emoji: bool=True):
        self._moses = MosesDetokenizer(lang="pl")
        self._detokenize = detokenize
        self._replace_emoji = replace_emoji

    def process(self, text: str) -> str:
        if self._replace_emoji:
            text = "".join((emoji.get(c, c) for c in text))
        tokens: List[str] = text.split()
        return self._moses.detokenize(tokens)